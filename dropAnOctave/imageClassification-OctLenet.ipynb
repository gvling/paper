{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-19T09:16:44.079076Z",
     "start_time": "2019-06-19T09:16:38.354372Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from utils import data\n",
    "from models.lenet import OctLenet as Lenet\n",
    "from utils.visualization import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-19T09:16:44.088658Z",
     "start_time": "2019-06-19T09:16:44.081588Z"
    }
   },
   "outputs": [],
   "source": [
    "bn = True\n",
    "# const\n",
    "taskName = 'fasionClassfiction'\n",
    "modelName = 'octLenet{}'.format('_bn' if bn else '')\n",
    "JST = timezone(timedelta(hours=+9), 'JST')\n",
    "now = datetime.now(JST)\n",
    "nowStr = now.strftime(\"%Y%m%d_%H%M%S\")\n",
    "showImgCount = 10\n",
    "\n",
    "imgHeight = 224\n",
    "imgWidth = 224\n",
    "imgChannel = 3\n",
    "imgShape = [-1, imgHeight, imgWidth, imgChannel]\n",
    "labelSize = 13\n",
    "tfrecordPath = './img/fashionDataset/tfrecord/dataset224.tfrecord'\n",
    "trainRatio = 0.7\n",
    "\n",
    "# hyper parameter\n",
    "bs = 32\n",
    "lr = 0.00001\n",
    "ep = 50\n",
    "alpha = 0.25\n",
    "\n",
    "logDir = '../logs/{}/{}/{}/'.format(taskName, modelName, nowStr)\n",
    "metadataDir = '{}metadata.tsv'.format(logDir)\n",
    "checkPointDir = '{}images.ckpt'.format(logDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-19T10:29:41.792529Z",
     "start_time": "2019-06-19T09:16:44.090282Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Train Accuracy: 0.6405 | Train Loss: 2.0556 | Test Accuracy: 0.7168 | Test Loss: 1.9737\n",
      "Epoch: 1 | Train Accuracy: 0.7560 | Train Loss: 1.9418 | Test Accuracy: 0.7785 | Test Loss: 1.9162\n",
      "Epoch: 2 | Train Accuracy: 0.8213 | Train Loss: 1.8764 | Test Accuracy: 0.8449 | Test Loss: 1.8502\n",
      "Epoch: 3 | Train Accuracy: 0.8514 | Train Loss: 1.8443 | Test Accuracy: 0.8491 | Test Loss: 1.8441\n",
      "Epoch: 4 | Train Accuracy: 0.8535 | Train Loss: 1.8404 | Test Accuracy: 0.8593 | Test Loss: 1.8326\n",
      "Epoch: 5 | Train Accuracy: 0.8581 | Train Loss: 1.8349 | Test Accuracy: 0.8634 | Test Loss: 1.8286\n",
      "Epoch: 6 | Train Accuracy: 0.8611 | Train Loss: 1.8318 | Test Accuracy: 0.8660 | Test Loss: 1.8256\n",
      "Epoch: 7 | Train Accuracy: 0.8608 | Train Loss: 1.8305 | Test Accuracy: 0.8610 | Test Loss: 1.8302\n",
      "Epoch: 8 | Train Accuracy: 0.8661 | Train Loss: 1.8254 | Test Accuracy: 0.8636 | Test Loss: 1.8268\n",
      "Epoch: 9 | Train Accuracy: 0.8645 | Train Loss: 1.8260 | Test Accuracy: 0.8643 | Test Loss: 1.8260\n",
      "Epoch: 10 | Train Accuracy: 0.8678 | Train Loss: 1.8230 | Test Accuracy: 0.8781 | Test Loss: 1.8121\n",
      "Epoch: 11 | Train Accuracy: 0.8664 | Train Loss: 1.8239 | Test Accuracy: 0.8706 | Test Loss: 1.8197\n",
      "Epoch: 12 | Train Accuracy: 0.8689 | Train Loss: 1.8211 | Test Accuracy: 0.8712 | Test Loss: 1.8186\n",
      "Epoch: 13 | Train Accuracy: 0.8674 | Train Loss: 1.8224 | Test Accuracy: 0.8717 | Test Loss: 1.8183\n",
      "Epoch: 14 | Train Accuracy: 0.8711 | Train Loss: 1.8188 | Test Accuracy: 0.8708 | Test Loss: 1.8181\n",
      "Epoch: 15 | Train Accuracy: 0.8695 | Train Loss: 1.8199 | Test Accuracy: 0.8685 | Test Loss: 1.8207\n",
      "Epoch: 16 | Train Accuracy: 0.8699 | Train Loss: 1.8195 | Test Accuracy: 0.8691 | Test Loss: 1.8199\n",
      "Epoch: 17 | Train Accuracy: 0.8704 | Train Loss: 1.8186 | Test Accuracy: 0.8728 | Test Loss: 1.8160\n",
      "Epoch: 18 | Train Accuracy: 0.8708 | Train Loss: 1.8182 | Test Accuracy: 0.8717 | Test Loss: 1.8168\n",
      "Epoch: 19 | Train Accuracy: 0.8719 | Train Loss: 1.8169 | Test Accuracy: 0.8694 | Test Loss: 1.8193\n",
      "Epoch: 20 | Train Accuracy: 0.8677 | Train Loss: 1.8207 | Test Accuracy: 0.8670 | Test Loss: 1.8234\n",
      "Epoch: 21 | Train Accuracy: 0.8723 | Train Loss: 1.8163 | Test Accuracy: 0.8730 | Test Loss: 1.8159\n",
      "Epoch: 22 | Train Accuracy: 0.8710 | Train Loss: 1.8174 | Test Accuracy: 0.8664 | Test Loss: 1.8215\n",
      "Epoch: 23 | Train Accuracy: 0.8728 | Train Loss: 1.8158 | Test Accuracy: 0.8702 | Test Loss: 1.8178\n",
      "Epoch: 24 | Train Accuracy: 0.8719 | Train Loss: 1.8164 | Test Accuracy: 0.8747 | Test Loss: 1.8142\n",
      "Epoch: 25 | Train Accuracy: 0.8746 | Train Loss: 1.8136 | Test Accuracy: 0.8709 | Test Loss: 1.8167\n",
      "Epoch: 26 | Train Accuracy: 0.8743 | Train Loss: 1.8135 | Test Accuracy: 0.8743 | Test Loss: 1.8134\n",
      "Epoch: 27 | Train Accuracy: 0.8731 | Train Loss: 1.8147 | Test Accuracy: 0.8743 | Test Loss: 1.8135\n",
      "Epoch: 28 | Train Accuracy: 0.8737 | Train Loss: 1.8143 | Test Accuracy: 0.8733 | Test Loss: 1.8138\n",
      "Epoch: 29 | Train Accuracy: 0.8740 | Train Loss: 1.8135 | Test Accuracy: 0.8719 | Test Loss: 1.8156\n",
      "Epoch: 30 | Train Accuracy: 0.8728 | Train Loss: 1.8148 | Test Accuracy: 0.8754 | Test Loss: 1.8120\n",
      "Epoch: 31 | Train Accuracy: 0.9358 | Train Loss: 1.7552 | Test Accuracy: 0.9355 | Test Loss: 1.7549\n",
      "Epoch: 32 | Train Accuracy: 0.9379 | Train Loss: 1.7522 | Test Accuracy: 0.9397 | Test Loss: 1.7500\n",
      "Epoch: 33 | Train Accuracy: 0.9397 | Train Loss: 1.7503 | Test Accuracy: 0.9399 | Test Loss: 1.7501\n",
      "Epoch: 34 | Train Accuracy: 0.9383 | Train Loss: 1.7514 | Test Accuracy: 0.9406 | Test Loss: 1.7493\n",
      "Epoch: 35 | Train Accuracy: 0.9399 | Train Loss: 1.7498 | Test Accuracy: 0.9393 | Test Loss: 1.7502\n",
      "Epoch: 36 | Train Accuracy: 0.9388 | Train Loss: 1.7508 | Test Accuracy: 0.9387 | Test Loss: 1.7506\n",
      "Epoch: 37 | Train Accuracy: 0.9400 | Train Loss: 1.7496 | Test Accuracy: 0.9405 | Test Loss: 1.7494\n",
      "Epoch: 38 | Train Accuracy: 0.9401 | Train Loss: 1.7494 | Test Accuracy: 0.9397 | Test Loss: 1.7498\n",
      "Epoch: 39 | Train Accuracy: 0.9395 | Train Loss: 1.7500 | Test Accuracy: 0.9363 | Test Loss: 1.7531\n",
      "Epoch: 40 | Train Accuracy: 0.9395 | Train Loss: 1.7500 | Test Accuracy: 0.9392 | Test Loss: 1.7503\n",
      "Epoch: 41 | Train Accuracy: 0.9405 | Train Loss: 1.7489 | Test Accuracy: 0.9388 | Test Loss: 1.7502\n",
      "Epoch: 42 | Train Accuracy: 0.9409 | Train Loss: 1.7484 | Test Accuracy: 0.9429 | Test Loss: 1.7464\n",
      "Epoch: 43 | Train Accuracy: 0.9382 | Train Loss: 1.7512 | Test Accuracy: 0.9423 | Test Loss: 1.7468\n",
      "Epoch: 44 | Train Accuracy: 0.9409 | Train Loss: 1.7486 | Test Accuracy: 0.9427 | Test Loss: 1.7466\n",
      "Epoch: 45 | Train Accuracy: 0.9396 | Train Loss: 1.7498 | Test Accuracy: 0.9408 | Test Loss: 1.7485\n",
      "Epoch: 46 | Train Accuracy: 0.9417 | Train Loss: 1.7476 | Test Accuracy: 0.9439 | Test Loss: 1.7453\n",
      "Epoch: 47 | Train Accuracy: 0.9406 | Train Loss: 1.7486 | Test Accuracy: 0.9416 | Test Loss: 1.7476\n",
      "Epoch: 48 | Train Accuracy: 0.9414 | Train Loss: 1.7481 | Test Accuracy: 0.9395 | Test Loss: 1.7502\n",
      "Epoch: 49 | Train Accuracy: 0.9397 | Train Loss: 1.7496 | Test Accuracy: 0.9402 | Test Loss: 1.7489\n"
     ]
    }
   ],
   "source": [
    "# main\n",
    "with tf.Graph().as_default():\n",
    "    # load data\n",
    "    with tf.variable_scope('tfrecord'):\n",
    "        tfrecord = data.TFRecord(tfrecordPath, labelSize)\n",
    "        dataset = tfrecord.toDataset()\n",
    "        # split dataset\n",
    "        tfrecord = data.TFRecord(tfrecordPath, labelSize)\n",
    "        dataset = tfrecord.toDataset()\n",
    "        trainSize, testSize, trainDataset, testDataset = tfrecord.splitDataset(bs, trainRatio)\n",
    "        trainIteration = trainSize // bs\n",
    "        testIteration = testSize // bs        \n",
    "        # TODO: data augmentation\n",
    "\n",
    "    # make iterator\n",
    "    with tf.variable_scope('train_data'):\n",
    "        trainIterator = trainDataset.make_initializable_iterator()\n",
    "        trainNextBatch = trainIterator.get_next(name='train_next_batch')\n",
    "        trainIteratorInitOp = trainIterator.initializer\n",
    "    with tf.variable_scope('test_data'):\n",
    "        testIterator = testDataset.make_initializable_iterator()\n",
    "        testNextBatch = testIterator.get_next(name='test_next_batch')\n",
    "        testIteratorInitOp = testIterator.initializer\n",
    "\n",
    "    \n",
    "    x = tf.placeholder(\"float\", [None, imgHeight, imgWidth, imgChannel], name='x')\n",
    "    y = tf.placeholder(\"float\", [None, labelSize], name='label')\n",
    "    isTrain = tf.placeholder(tf.bool, name='is_train')\n",
    "    \n",
    "    network = Lenet(alpha, x, inputReshapeTo=imgShape, labelSize=labelSize, batchNorm=bn, visualization=True)\n",
    "    _ = network.inference(isTrain)\n",
    "    cost = network.loss(y)\n",
    "    optimizer = tf.train.AdamOptimizer(lr)\n",
    "    accuracy = network.accuracy(y)\n",
    "    trainOp = network.training(cost, optimizer)\n",
    "    drawHist = tf.summary.merge_all('histogram')\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    config = tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True))\n",
    "    sess = tf.Session(config=config)\n",
    "    summaryWriter = tf.summary.FileWriter(logDir, graph=sess.graph)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # Training cycle\n",
    "    for e in range(ep):\n",
    "        trainAvgAcc = trainAvgLoss = testAvgAcc = testAvgLoss = 0.\n",
    "        # train\n",
    "        sess.run(trainIteratorInitOp)\n",
    "        for i in range(trainIteration):\n",
    "            _, batchX, batchY = sess.run(trainNextBatch)\n",
    "            _, l, a = sess.run([trainOp, cost, accuracy], feed_dict={x: batchX, y: batchY, isTrain: True})\n",
    "            trainAvgAcc += a / trainIteration\n",
    "            trainAvgLoss += l / trainIteration\n",
    "\n",
    "        # validation\n",
    "        sess.run(testIteratorInitOp)\n",
    "        for i in range(testIteration):\n",
    "            _, testBatchX, testBatchY = sess.run(testNextBatch)\n",
    "            l, a, histogram = sess.run([cost, accuracy, drawHist], feed_dict={x: testBatchX, y: testBatchY, isTrain: False})\n",
    "            testAvgAcc += a / testIteration\n",
    "            testAvgLoss += l / testIteration\n",
    "\n",
    "        # tensorBoard\n",
    "        summaryWriter.add_summary(drawSclar('train', {'acc': trainAvgAcc, 'loss': trainAvgLoss}), global_step=e)\n",
    "        summaryWriter.add_summary(drawSclar('validation', {'acc': testAvgAcc, 'loss': testAvgLoss}), global_step=e)\n",
    "        summaryWriter.add_summary(histogram, global_step=e)\n",
    "        saver.save(sess, checkPointDir, global_step=e)\n",
    "        print('Epoch: {} | Train Accuracy: {:.4f} | Train Loss: {:.4f} | Test Accuracy: {:.4f} | Test Loss: {:.4f}'.format(e, trainAvgAcc, trainAvgLoss, testAvgAcc, testAvgLoss))\n",
    "    summaryWriter.close()\n",
    "    sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

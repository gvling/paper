{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T11:45:56.415351Z",
     "start_time": "2019-06-17T11:45:48.663962Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from utils import data\n",
    "from models.lenet import Lenet as Lenet\n",
    "from utils.visualization import *\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T11:45:57.087089Z",
     "start_time": "2019-06-17T11:45:56.417737Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-a8e4704392b5>:22: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "bn = True\n",
    "# const\n",
    "taskName = 'mnist'\n",
    "modelName = 'lenet{}'.format('_bn' if bn else '')\n",
    "JST = timezone(timedelta(hours=+9), 'JST')\n",
    "now = datetime.now(JST)\n",
    "nowStr = now.strftime(\"%Y%m%d_%H%M%S\")\n",
    "showImgCount = 10\n",
    "\n",
    "imgHeight = 28\n",
    "imgWidth = 28\n",
    "imgChannel = 1\n",
    "imgShape = [-1, imgHeight, imgWidth, imgChannel]\n",
    "labelSize = 10\n",
    "\n",
    "# hyper parameter\n",
    "bs = 64\n",
    "lr = 0.0001\n",
    "ep = 50\n",
    "\n",
    "logDir = '../logs/{}/{}/{}/'.format(taskName, modelName, nowStr)\n",
    "mnist = input_data.read_data_sets(\"data/\", one_hot=True)\n",
    "checkPointDir = '{}images.ckpt'.format(logDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T11:54:10.114130Z",
     "start_time": "2019-06-17T11:45:57.095266Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Train Accuracy: 0.7358 | Train Loss: 1.7651 | Test Accuracy: 0.9221 | Test Loss: 1.5804\n",
      "Epoch: 1 | Train Accuracy: 0.9467 | Train Loss: 1.5336 | Test Accuracy: 0.9623 | Test Loss: 1.5100\n",
      "Epoch: 2 | Train Accuracy: 0.9634 | Train Loss: 1.5085 | Test Accuracy: 0.9710 | Test Loss: 1.4986\n",
      "Epoch: 3 | Train Accuracy: 0.9704 | Train Loss: 1.4987 | Test Accuracy: 0.9740 | Test Loss: 1.4932\n",
      "Epoch: 4 | Train Accuracy: 0.9751 | Train Loss: 1.4924 | Test Accuracy: 0.9774 | Test Loss: 1.4892\n",
      "Epoch: 5 | Train Accuracy: 0.9786 | Train Loss: 1.4884 | Test Accuracy: 0.9792 | Test Loss: 1.4864\n",
      "Epoch: 6 | Train Accuracy: 0.9810 | Train Loss: 1.4850 | Test Accuracy: 0.9812 | Test Loss: 1.4845\n",
      "Epoch: 7 | Train Accuracy: 0.9829 | Train Loss: 1.4830 | Test Accuracy: 0.9808 | Test Loss: 1.4831\n",
      "Epoch: 8 | Train Accuracy: 0.9844 | Train Loss: 1.4810 | Test Accuracy: 0.9826 | Test Loss: 1.4818\n",
      "Epoch: 9 | Train Accuracy: 0.9851 | Train Loss: 1.4796 | Test Accuracy: 0.9820 | Test Loss: 1.4816\n",
      "Epoch: 10 | Train Accuracy: 0.9866 | Train Loss: 1.4780 | Test Accuracy: 0.9852 | Test Loss: 1.4790\n",
      "Epoch: 11 | Train Accuracy: 0.9872 | Train Loss: 1.4771 | Test Accuracy: 0.9848 | Test Loss: 1.4790\n",
      "Epoch: 12 | Train Accuracy: 0.9882 | Train Loss: 1.4759 | Test Accuracy: 0.9860 | Test Loss: 1.4778\n",
      "Epoch: 13 | Train Accuracy: 0.9886 | Train Loss: 1.4752 | Test Accuracy: 0.9858 | Test Loss: 1.4780\n",
      "Epoch: 14 | Train Accuracy: 0.9898 | Train Loss: 1.4743 | Test Accuracy: 0.9842 | Test Loss: 1.4785\n",
      "Epoch: 15 | Train Accuracy: 0.9905 | Train Loss: 1.4735 | Test Accuracy: 0.9860 | Test Loss: 1.4774\n",
      "Epoch: 16 | Train Accuracy: 0.9906 | Train Loss: 1.4730 | Test Accuracy: 0.9862 | Test Loss: 1.4769\n",
      "Epoch: 17 | Train Accuracy: 0.9910 | Train Loss: 1.4725 | Test Accuracy: 0.9874 | Test Loss: 1.4760\n",
      "Epoch: 18 | Train Accuracy: 0.9918 | Train Loss: 1.4716 | Test Accuracy: 0.9890 | Test Loss: 1.4754\n",
      "Epoch: 19 | Train Accuracy: 0.9923 | Train Loss: 1.4712 | Test Accuracy: 0.9890 | Test Loss: 1.4751\n",
      "Epoch: 20 | Train Accuracy: 0.9925 | Train Loss: 1.4709 | Test Accuracy: 0.9878 | Test Loss: 1.4754\n",
      "Epoch: 21 | Train Accuracy: 0.9929 | Train Loss: 1.4703 | Test Accuracy: 0.9858 | Test Loss: 1.4759\n",
      "Epoch: 22 | Train Accuracy: 0.9931 | Train Loss: 1.4699 | Test Accuracy: 0.9880 | Test Loss: 1.4760\n",
      "Epoch: 23 | Train Accuracy: 0.9934 | Train Loss: 1.4695 | Test Accuracy: 0.9878 | Test Loss: 1.4747\n",
      "Epoch: 24 | Train Accuracy: 0.9938 | Train Loss: 1.4692 | Test Accuracy: 0.9886 | Test Loss: 1.4749\n",
      "Epoch: 25 | Train Accuracy: 0.9938 | Train Loss: 1.4689 | Test Accuracy: 0.9890 | Test Loss: 1.4744\n",
      "Epoch: 26 | Train Accuracy: 0.9943 | Train Loss: 1.4686 | Test Accuracy: 0.9890 | Test Loss: 1.4738\n",
      "Epoch: 27 | Train Accuracy: 0.9945 | Train Loss: 1.4683 | Test Accuracy: 0.9888 | Test Loss: 1.4741\n",
      "Epoch: 28 | Train Accuracy: 0.9947 | Train Loss: 1.4679 | Test Accuracy: 0.9888 | Test Loss: 1.4740\n",
      "Epoch: 29 | Train Accuracy: 0.9952 | Train Loss: 1.4675 | Test Accuracy: 0.9898 | Test Loss: 1.4730\n",
      "Epoch: 30 | Train Accuracy: 0.9951 | Train Loss: 1.4675 | Test Accuracy: 0.9886 | Test Loss: 1.4741\n",
      "Epoch: 31 | Train Accuracy: 0.9953 | Train Loss: 1.4671 | Test Accuracy: 0.9894 | Test Loss: 1.4726\n",
      "Epoch: 32 | Train Accuracy: 0.9953 | Train Loss: 1.4669 | Test Accuracy: 0.9890 | Test Loss: 1.4739\n",
      "Epoch: 33 | Train Accuracy: 0.9954 | Train Loss: 1.4668 | Test Accuracy: 0.9890 | Test Loss: 1.4734\n",
      "Epoch: 34 | Train Accuracy: 0.9957 | Train Loss: 1.4666 | Test Accuracy: 0.9898 | Test Loss: 1.4723\n",
      "Epoch: 35 | Train Accuracy: 0.9959 | Train Loss: 1.4664 | Test Accuracy: 0.9884 | Test Loss: 1.4737\n",
      "Epoch: 36 | Train Accuracy: 0.9959 | Train Loss: 1.4663 | Test Accuracy: 0.9888 | Test Loss: 1.4735\n",
      "Epoch: 37 | Train Accuracy: 0.9959 | Train Loss: 1.4661 | Test Accuracy: 0.9892 | Test Loss: 1.4736\n",
      "Epoch: 38 | Train Accuracy: 0.9960 | Train Loss: 1.4661 | Test Accuracy: 0.9866 | Test Loss: 1.4754\n",
      "Epoch: 39 | Train Accuracy: 0.9962 | Train Loss: 1.4657 | Test Accuracy: 0.9892 | Test Loss: 1.4727\n",
      "Epoch: 40 | Train Accuracy: 0.9963 | Train Loss: 1.4657 | Test Accuracy: 0.9874 | Test Loss: 1.4744\n",
      "Epoch: 41 | Train Accuracy: 0.9962 | Train Loss: 1.4657 | Test Accuracy: 0.9900 | Test Loss: 1.4728\n",
      "Epoch: 42 | Train Accuracy: 0.9964 | Train Loss: 1.4654 | Test Accuracy: 0.9890 | Test Loss: 1.4735\n",
      "Epoch: 43 | Train Accuracy: 0.9964 | Train Loss: 1.4654 | Test Accuracy: 0.9890 | Test Loss: 1.4733\n",
      "Epoch: 44 | Train Accuracy: 0.9966 | Train Loss: 1.4653 | Test Accuracy: 0.9888 | Test Loss: 1.4732\n",
      "Epoch: 45 | Train Accuracy: 0.9966 | Train Loss: 1.4652 | Test Accuracy: 0.9886 | Test Loss: 1.4728\n",
      "Epoch: 46 | Train Accuracy: 0.9967 | Train Loss: 1.4650 | Test Accuracy: 0.9892 | Test Loss: 1.4727\n",
      "Epoch: 47 | Train Accuracy: 0.9969 | Train Loss: 1.4649 | Test Accuracy: 0.9890 | Test Loss: 1.4733\n",
      "Epoch: 48 | Train Accuracy: 0.9968 | Train Loss: 1.4650 | Test Accuracy: 0.9888 | Test Loss: 1.4727\n",
      "Epoch: 49 | Train Accuracy: 0.9970 | Train Loss: 1.4646 | Test Accuracy: 0.9892 | Test Loss: 1.4734\n"
     ]
    }
   ],
   "source": [
    "# main\n",
    "with tf.Graph().as_default():\n",
    "    trainIteration = mnist.train.num_examples // bs\n",
    "    testIteration = mnist.validation.num_examples // bs\n",
    "    x = tf.placeholder(\"float\", [None, imgHeight * imgWidth * imgChannel], name='x')\n",
    "    y = tf.placeholder(\"float\", [None, labelSize], name='label')\n",
    "    isTrain = tf.placeholder(tf.bool, name='is_train')\n",
    "    \n",
    "    network = Lenet(x, inputReshapeTo=imgShape, labelSize=labelSize, batchNorm=bn, visualization=True)\n",
    "    _ = network.inference(isTrain)\n",
    "    cost = network.loss(y)\n",
    "    optimizer = tf.train.AdamOptimizer(lr)\n",
    "    accuracy = network.accuracy(y)\n",
    "    trainOp = network.training(cost, optimizer)\n",
    "    drawHist = tf.summary.merge_all('histogram')\n",
    "\n",
    "    # tensor board\n",
    "    # TODO: draw hist\n",
    "#    allVariables = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    config = tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True))\n",
    "    sess = tf.Session(config=config)\n",
    "    summaryWriter = tf.summary.FileWriter(logDir, graph=sess.graph)\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Training cycle\n",
    "    for e in range(ep):\n",
    "        trainAvgAcc = trainAvgLoss = testAvgAcc = testAvgLoss = 0.\n",
    "        # train\n",
    "        #sess.run(trainIteratorInitOp)\n",
    "        for i in range(trainIteration):\n",
    "            batchX, batchY = mnist.train.next_batch(bs)\n",
    "            _, l, a, histogram = sess.run([trainOp, cost, accuracy, drawHist], feed_dict={x: batchX, y: batchY, isTrain: True})\n",
    "            trainAvgAcc += a / trainIteration\n",
    "            trainAvgLoss += l / trainIteration\n",
    "\n",
    "        # validation\n",
    "        for i in range(testIteration):\n",
    "            testBatchX, testBatchY = mnist.validation.next_batch(bs)\n",
    "            l, a = sess.run([cost, accuracy], feed_dict={x: testBatchX, y: testBatchY, isTrain: False})\n",
    "            testAvgAcc += a / testIteration\n",
    "            testAvgLoss += l / testIteration\n",
    "\n",
    "        # tensorBoard\n",
    "        summaryWriter.add_summary(drawSclar('validation', {'acc': testAvgAcc, 'loss': testAvgLoss}), global_step=e)\n",
    "        summaryWriter.add_summary(drawSclar('train', {'acc': trainAvgAcc, 'loss': trainAvgLoss}), global_step=e)\n",
    "        summaryWriter.add_summary(histogram, global_step=e)\n",
    "        saver.save(sess, checkPointDir, global_step=e)\n",
    "        print('Epoch: {} | Train Accuracy: {:.4f} | Train Loss: {:.4f} | Test Accuracy: {:.4f} | Test Loss: {:.4f}'.format(e, trainAvgAcc, trainAvgLoss, testAvgAcc, testAvgLoss))\n",
    "    summaryWriter.close()\n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

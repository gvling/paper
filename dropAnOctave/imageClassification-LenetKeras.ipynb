{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-18T04:29:41.633814Z",
     "start_time": "2019-06-18T04:29:32.491858Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from utils import data\n",
    "from models.lenet import LenetKeras as Lenet\n",
    "from utils.visualization import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-18T04:29:41.644747Z",
     "start_time": "2019-06-18T04:29:41.636516Z"
    }
   },
   "outputs": [],
   "source": [
    "bn = True\n",
    "# const\n",
    "taskName = 'fasionClassfiction'\n",
    "modelName = 'lenetKeras{}'.format('_bn' if bn else '')\n",
    "JST = timezone(timedelta(hours=+9), 'JST')\n",
    "now = datetime.now(JST)\n",
    "nowStr = now.strftime(\"%Y%m%d_%H%M%S\")\n",
    "showImgCount = 10\n",
    "\n",
    "imgHeight = 224\n",
    "imgWidth = 224\n",
    "imgChannel = 3\n",
    "imgShape = [-1, imgHeight, imgWidth, imgChannel]\n",
    "labelSize = 13\n",
    "tfrecordPath = './img/fashionDataset/tfrecord/dataset224.tfrecord'\n",
    "trainRatio = 0.7\n",
    "\n",
    "# hyper parameter\n",
    "bs = 32\n",
    "lr = 0.00001\n",
    "ep = 50\n",
    "\n",
    "logDir = '../logs/{}/{}/{}/'.format(taskName, modelName, nowStr)\n",
    "metadataDir = '{}metadata.tsv'.format(logDir)\n",
    "checkPointDir = '{}images.ckpt'.format(logDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-18T05:26:35.269472Z",
     "start_time": "2019-06-18T04:29:41.646672Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name conv_1/conv2d/kernel:0 is illegal; using conv_1/conv2d/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name conv_1/conv2d/bias:0 is illegal; using conv_1/conv2d/bias_0 instead.\n",
      "INFO:tensorflow:Summary name conv_1/batch_normalization/gamma:0 is illegal; using conv_1/batch_normalization/gamma_0 instead.\n",
      "INFO:tensorflow:Summary name conv_1/batch_normalization/beta:0 is illegal; using conv_1/batch_normalization/beta_0 instead.\n",
      "INFO:tensorflow:Summary name conv_1/batch_normalization/moving_mean:0 is illegal; using conv_1/batch_normalization/moving_mean_0 instead.\n",
      "INFO:tensorflow:Summary name conv_1/batch_normalization/moving_variance:0 is illegal; using conv_1/batch_normalization/moving_variance_0 instead.\n",
      "INFO:tensorflow:Summary name conv_2/conv2d_1/kernel:0 is illegal; using conv_2/conv2d_1/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name conv_2/conv2d_1/bias:0 is illegal; using conv_2/conv2d_1/bias_0 instead.\n",
      "INFO:tensorflow:Summary name conv_2/batch_normalization_1/gamma:0 is illegal; using conv_2/batch_normalization_1/gamma_0 instead.\n",
      "INFO:tensorflow:Summary name conv_2/batch_normalization_1/beta:0 is illegal; using conv_2/batch_normalization_1/beta_0 instead.\n",
      "INFO:tensorflow:Summary name conv_2/batch_normalization_1/moving_mean:0 is illegal; using conv_2/batch_normalization_1/moving_mean_0 instead.\n",
      "INFO:tensorflow:Summary name conv_2/batch_normalization_1/moving_variance:0 is illegal; using conv_2/batch_normalization_1/moving_variance_0 instead.\n",
      "INFO:tensorflow:Summary name fc/fc1/kernel:0 is illegal; using fc/fc1/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name fc/fc1/bias:0 is illegal; using fc/fc1/bias_0 instead.\n",
      "INFO:tensorflow:Summary name output/softmax/kernel:0 is illegal; using output/softmax/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name output/softmax/bias:0 is illegal; using output/softmax/bias_0 instead.\n",
      "INFO:tensorflow:Summary name beta1_power:0 is illegal; using beta1_power_0 instead.\n",
      "INFO:tensorflow:Summary name beta2_power:0 is illegal; using beta2_power_0 instead.\n",
      "INFO:tensorflow:Summary name conv_1/conv2d/kernel/Adam:0 is illegal; using conv_1/conv2d/kernel/Adam_0 instead.\n",
      "INFO:tensorflow:Summary name conv_1/conv2d/kernel/Adam_1:0 is illegal; using conv_1/conv2d/kernel/Adam_1_0 instead.\n",
      "INFO:tensorflow:Summary name conv_1/conv2d/bias/Adam:0 is illegal; using conv_1/conv2d/bias/Adam_0 instead.\n",
      "INFO:tensorflow:Summary name conv_1/conv2d/bias/Adam_1:0 is illegal; using conv_1/conv2d/bias/Adam_1_0 instead.\n",
      "INFO:tensorflow:Summary name conv_1/batch_normalization/gamma/Adam:0 is illegal; using conv_1/batch_normalization/gamma/Adam_0 instead.\n",
      "INFO:tensorflow:Summary name conv_1/batch_normalization/gamma/Adam_1:0 is illegal; using conv_1/batch_normalization/gamma/Adam_1_0 instead.\n",
      "INFO:tensorflow:Summary name conv_1/batch_normalization/beta/Adam:0 is illegal; using conv_1/batch_normalization/beta/Adam_0 instead.\n",
      "INFO:tensorflow:Summary name conv_1/batch_normalization/beta/Adam_1:0 is illegal; using conv_1/batch_normalization/beta/Adam_1_0 instead.\n",
      "INFO:tensorflow:Summary name conv_2/conv2d_1/kernel/Adam:0 is illegal; using conv_2/conv2d_1/kernel/Adam_0 instead.\n",
      "INFO:tensorflow:Summary name conv_2/conv2d_1/kernel/Adam_1:0 is illegal; using conv_2/conv2d_1/kernel/Adam_1_0 instead.\n",
      "INFO:tensorflow:Summary name conv_2/conv2d_1/bias/Adam:0 is illegal; using conv_2/conv2d_1/bias/Adam_0 instead.\n",
      "INFO:tensorflow:Summary name conv_2/conv2d_1/bias/Adam_1:0 is illegal; using conv_2/conv2d_1/bias/Adam_1_0 instead.\n",
      "INFO:tensorflow:Summary name conv_2/batch_normalization_1/gamma/Adam:0 is illegal; using conv_2/batch_normalization_1/gamma/Adam_0 instead.\n",
      "INFO:tensorflow:Summary name conv_2/batch_normalization_1/gamma/Adam_1:0 is illegal; using conv_2/batch_normalization_1/gamma/Adam_1_0 instead.\n",
      "INFO:tensorflow:Summary name conv_2/batch_normalization_1/beta/Adam:0 is illegal; using conv_2/batch_normalization_1/beta/Adam_0 instead.\n",
      "INFO:tensorflow:Summary name conv_2/batch_normalization_1/beta/Adam_1:0 is illegal; using conv_2/batch_normalization_1/beta/Adam_1_0 instead.\n",
      "INFO:tensorflow:Summary name fc/fc1/kernel/Adam:0 is illegal; using fc/fc1/kernel/Adam_0 instead.\n",
      "INFO:tensorflow:Summary name fc/fc1/kernel/Adam_1:0 is illegal; using fc/fc1/kernel/Adam_1_0 instead.\n",
      "INFO:tensorflow:Summary name fc/fc1/bias/Adam:0 is illegal; using fc/fc1/bias/Adam_0 instead.\n",
      "INFO:tensorflow:Summary name fc/fc1/bias/Adam_1:0 is illegal; using fc/fc1/bias/Adam_1_0 instead.\n",
      "INFO:tensorflow:Summary name output/softmax/kernel/Adam:0 is illegal; using output/softmax/kernel/Adam_0 instead.\n",
      "INFO:tensorflow:Summary name output/softmax/kernel/Adam_1:0 is illegal; using output/softmax/kernel/Adam_1_0 instead.\n",
      "INFO:tensorflow:Summary name output/softmax/bias/Adam:0 is illegal; using output/softmax/bias/Adam_0 instead.\n",
      "INFO:tensorflow:Summary name output/softmax/bias/Adam_1:0 is illegal; using output/softmax/bias/Adam_1_0 instead.\n",
      "Epoch: 0 | Train Accuracy: 0.3841 | Train Loss: 2.3129 | Test Accuracy: 0.3907 | Test Loss: 2.2985\n",
      "Epoch: 1 | Train Accuracy: 0.3865 | Train Loss: 2.3026 | Test Accuracy: 0.3791 | Test Loss: 2.3101\n",
      "Epoch: 2 | Train Accuracy: 0.3874 | Train Loss: 2.3017 | Test Accuracy: 0.3882 | Test Loss: 2.3009\n",
      "Epoch: 3 | Train Accuracy: 0.3839 | Train Loss: 2.3051 | Test Accuracy: 0.3886 | Test Loss: 2.3005\n",
      "Epoch: 4 | Train Accuracy: 0.3874 | Train Loss: 2.3017 | Test Accuracy: 0.3819 | Test Loss: 2.3072\n",
      "Epoch: 5 | Train Accuracy: 0.4686 | Train Loss: 2.2250 | Test Accuracy: 0.5715 | Test Loss: 2.1196\n",
      "Epoch: 6 | Train Accuracy: 0.5725 | Train Loss: 2.1158 | Test Accuracy: 0.5792 | Test Loss: 2.1077\n",
      "Epoch: 7 | Train Accuracy: 0.5757 | Train Loss: 2.1116 | Test Accuracy: 0.6255 | Test Loss: 2.0642\n",
      "Epoch: 8 | Train Accuracy: 0.6653 | Train Loss: 2.0306 | Test Accuracy: 0.6918 | Test Loss: 2.0031\n",
      "Epoch: 9 | Train Accuracy: 0.6942 | Train Loss: 1.9989 | Test Accuracy: 0.7069 | Test Loss: 1.9877\n",
      "Epoch: 10 | Train Accuracy: 0.7133 | Train Loss: 1.9806 | Test Accuracy: 0.7134 | Test Loss: 1.9774\n",
      "Epoch: 11 | Train Accuracy: 0.7172 | Train Loss: 1.9739 | Test Accuracy: 0.7103 | Test Loss: 1.9797\n",
      "Epoch: 12 | Train Accuracy: 0.7189 | Train Loss: 1.9714 | Test Accuracy: 0.7201 | Test Loss: 1.9700\n",
      "Epoch: 13 | Train Accuracy: 0.7209 | Train Loss: 1.9686 | Test Accuracy: 0.7280 | Test Loss: 1.9615\n",
      "Epoch: 14 | Train Accuracy: 0.7181 | Train Loss: 1.9711 | Test Accuracy: 0.7208 | Test Loss: 1.9698\n",
      "Epoch: 15 | Train Accuracy: 0.7234 | Train Loss: 1.9655 | Test Accuracy: 0.7189 | Test Loss: 1.9704\n",
      "Epoch: 16 | Train Accuracy: 0.7265 | Train Loss: 1.9625 | Test Accuracy: 0.7276 | Test Loss: 1.9607\n",
      "Epoch: 17 | Train Accuracy: 0.7260 | Train Loss: 1.9625 | Test Accuracy: 0.7246 | Test Loss: 1.9633\n",
      "Epoch: 18 | Train Accuracy: 0.7274 | Train Loss: 1.9605 | Test Accuracy: 0.7320 | Test Loss: 1.9557\n",
      "Epoch: 19 | Train Accuracy: 0.7268 | Train Loss: 1.9611 | Test Accuracy: 0.7144 | Test Loss: 1.9721\n",
      "Epoch: 20 | Train Accuracy: 0.7270 | Train Loss: 1.9606 | Test Accuracy: 0.7279 | Test Loss: 1.9597\n",
      "Epoch: 21 | Train Accuracy: 0.7294 | Train Loss: 1.9589 | Test Accuracy: 0.7550 | Test Loss: 1.9355\n",
      "Epoch: 22 | Train Accuracy: 0.7455 | Train Loss: 1.9438 | Test Accuracy: 0.7507 | Test Loss: 1.9388\n",
      "Epoch: 23 | Train Accuracy: 0.7488 | Train Loss: 1.9397 | Test Accuracy: 0.7449 | Test Loss: 1.9430\n",
      "Epoch: 24 | Train Accuracy: 0.7476 | Train Loss: 1.9403 | Test Accuracy: 0.7531 | Test Loss: 1.9343\n",
      "Epoch: 25 | Train Accuracy: 0.7505 | Train Loss: 1.9370 | Test Accuracy: 0.7543 | Test Loss: 1.9336\n",
      "Epoch: 26 | Train Accuracy: 0.7483 | Train Loss: 1.9392 | Test Accuracy: 0.7518 | Test Loss: 1.9355\n",
      "Epoch: 27 | Train Accuracy: 0.7507 | Train Loss: 1.9365 | Test Accuracy: 0.7445 | Test Loss: 1.9429\n",
      "Epoch: 28 | Train Accuracy: 0.7489 | Train Loss: 1.9378 | Test Accuracy: 0.7457 | Test Loss: 1.9406\n",
      "Epoch: 29 | Train Accuracy: 0.7750 | Train Loss: 1.9152 | Test Accuracy: 0.8343 | Test Loss: 1.8645\n",
      "Epoch: 30 | Train Accuracy: 0.8478 | Train Loss: 1.8483 | Test Accuracy: 0.8475 | Test Loss: 1.8483\n",
      "Epoch: 31 | Train Accuracy: 0.8515 | Train Loss: 1.8427 | Test Accuracy: 0.8550 | Test Loss: 1.8370\n",
      "Epoch: 32 | Train Accuracy: 0.8525 | Train Loss: 1.8404 | Test Accuracy: 0.8507 | Test Loss: 1.8424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 33 | Train Accuracy: 0.8520 | Train Loss: 1.8403 | Test Accuracy: 0.8496 | Test Loss: 1.8419\n",
      "Epoch: 34 | Train Accuracy: 0.8549 | Train Loss: 1.8372 | Test Accuracy: 0.8543 | Test Loss: 1.8372\n",
      "Epoch: 35 | Train Accuracy: 0.8564 | Train Loss: 1.8353 | Test Accuracy: 0.8543 | Test Loss: 1.8369\n",
      "Epoch: 36 | Train Accuracy: 0.8565 | Train Loss: 1.8347 | Test Accuracy: 0.8572 | Test Loss: 1.8345\n",
      "Epoch: 37 | Train Accuracy: 0.8567 | Train Loss: 1.8345 | Test Accuracy: 0.8538 | Test Loss: 1.8381\n",
      "Epoch: 38 | Train Accuracy: 0.8553 | Train Loss: 1.8356 | Test Accuracy: 0.8538 | Test Loss: 1.8364\n",
      "Epoch: 39 | Train Accuracy: 0.8578 | Train Loss: 1.8331 | Test Accuracy: 0.8560 | Test Loss: 1.8353\n",
      "Epoch: 40 | Train Accuracy: 0.8595 | Train Loss: 1.8312 | Test Accuracy: 0.8571 | Test Loss: 1.8328\n",
      "Epoch: 41 | Train Accuracy: 0.8553 | Train Loss: 1.8360 | Test Accuracy: 0.8559 | Test Loss: 1.8351\n",
      "Epoch: 42 | Train Accuracy: 0.8597 | Train Loss: 1.8316 | Test Accuracy: 0.8549 | Test Loss: 1.8348\n",
      "Epoch: 43 | Train Accuracy: 0.8590 | Train Loss: 1.8315 | Test Accuracy: 0.8614 | Test Loss: 1.8293\n",
      "Epoch: 44 | Train Accuracy: 0.8620 | Train Loss: 1.8283 | Test Accuracy: 0.8607 | Test Loss: 1.8292\n",
      "Epoch: 45 | Train Accuracy: 0.8593 | Train Loss: 1.8309 | Test Accuracy: 0.8526 | Test Loss: 1.8375\n",
      "Epoch: 46 | Train Accuracy: 0.8609 | Train Loss: 1.8290 | Test Accuracy: 0.8661 | Test Loss: 1.8249\n",
      "Epoch: 47 | Train Accuracy: 0.8608 | Train Loss: 1.8297 | Test Accuracy: 0.8668 | Test Loss: 1.8239\n",
      "Epoch: 48 | Train Accuracy: 0.8614 | Train Loss: 1.8288 | Test Accuracy: 0.8600 | Test Loss: 1.8299\n",
      "Epoch: 49 | Train Accuracy: 0.8710 | Train Loss: 1.8210 | Test Accuracy: 0.8823 | Test Loss: 1.8097\n"
     ]
    }
   ],
   "source": [
    "# main\n",
    "with tf.Graph().as_default():\n",
    "    # load data\n",
    "    with tf.variable_scope('tfrecord'):\n",
    "        tfrecord = data.TFRecord(tfrecordPath, labelSize)\n",
    "        dataset = tfrecord.toDataset()\n",
    "        # split dataset\n",
    "        tfrecord = data.TFRecord(tfrecordPath, labelSize)\n",
    "        dataset = tfrecord.toDataset()\n",
    "        trainSize, testSize, trainDataset, testDataset = tfrecord.splitDataset(bs, trainRatio)\n",
    "        trainIteration = trainSize // bs\n",
    "        testIteration = testSize // bs        \n",
    "        # TODO: data augmentation\n",
    "\n",
    "    # make iterator\n",
    "    with tf.variable_scope('train_data'):\n",
    "        trainIterator = trainDataset.make_initializable_iterator()\n",
    "        trainNextBatch = trainIterator.get_next(name='train_next_batch')\n",
    "        trainIteratorInitOp = trainIterator.initializer\n",
    "    with tf.variable_scope('test_data'):\n",
    "        testIterator = testDataset.make_initializable_iterator()\n",
    "        testNextBatch = testIterator.get_next(name='test_next_batch')\n",
    "        testIteratorInitOp = testIterator.initializer\n",
    "\n",
    "    \n",
    "    x = tf.placeholder(\"float\", [None, imgHeight, imgWidth, imgChannel], name='x')\n",
    "    y = tf.placeholder(\"float\", [None, labelSize], name='label')\n",
    "    isTrain = tf.placeholder(tf.bool, name='is_train')\n",
    "    \n",
    "    network = Lenet(x, inputReshapeTo=imgShape, labelSize=labelSize, batchNorm=bn)\n",
    "    _ = network.inference(isTrain)\n",
    "    cost = network.loss(y)\n",
    "    optimizer = tf.train.AdamOptimizer(lr)\n",
    "    accuracy = network.accuracy(y)\n",
    "    trainOp = network.training(cost, optimizer)\n",
    "    \n",
    "    # tensorBoard\n",
    "    allVariables = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "    drawOp = []\n",
    "    for v in allVariables:\n",
    "        op = tf.summary.histogram(v.name, v)\n",
    "        drawOp.append(op)\n",
    "    summaryOp = tf.summary.merge([drawOp])\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    config = tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True))\n",
    "    sess = tf.Session(config=config)\n",
    "    summaryWriter = tf.summary.FileWriter(logDir, graph=sess.graph)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for e in range(ep):\n",
    "        trainAvgAcc = trainAvgLoss = testAvgAcc = testAvgLoss = 0.\n",
    "        # train\n",
    "        sess.run(trainIteratorInitOp)\n",
    "        for i in range(trainIteration):\n",
    "            _, batchX, batchY = sess.run(trainNextBatch)\n",
    "            _, l, a = sess.run([trainOp, cost, accuracy], feed_dict={x: batchX, y: batchY, isTrain: True})\n",
    "            trainAvgAcc += a / trainIteration\n",
    "            trainAvgLoss += l / trainIteration\n",
    "\n",
    "        # validation\n",
    "        sess.run(testIteratorInitOp)\n",
    "        for i in range(testIteration):\n",
    "            _, testBatchX, testBatchY = sess.run(testNextBatch)\n",
    "            l, a, summary = sess.run([cost, accuracy, summaryOp], feed_dict={x: testBatchX, y: testBatchY, isTrain: False})\n",
    "            testAvgAcc += a / testIteration\n",
    "            testAvgLoss += l / testIteration\n",
    "\n",
    "        # tensorBoard\n",
    "        summaryWriter.add_summary(drawSclar('train', {'acc': trainAvgAcc, 'loss': trainAvgLoss}), global_step=e)\n",
    "        summaryWriter.add_summary(drawSclar('validation', {'acc': testAvgAcc, 'loss': testAvgLoss}), global_step=e)\n",
    "        summaryWriter.add_summary(summary, global_step=e)\n",
    "        saver.save(sess, checkPointDir, global_step=e)\n",
    "        print('Epoch: {} | Train Accuracy: {:.4f} | Train Loss: {:.4f} | Test Accuracy: {:.4f} | Test Loss: {:.4f}'.format(e, trainAvgAcc, trainAvgLoss, testAvgAcc, testAvgLoss))\n",
    "    summaryWriter.close()\n",
    "    sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

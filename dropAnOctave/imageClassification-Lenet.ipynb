{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T11:43:12.731792Z",
     "start_time": "2019-06-17T11:43:04.434073Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from utils import data\n",
    "from models.lenet import Lenet as Lenet\n",
    "from utils.visualization import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T11:43:12.769264Z",
     "start_time": "2019-06-17T11:43:12.743486Z"
    }
   },
   "outputs": [],
   "source": [
    "bn = True\n",
    "# const\n",
    "taskName = 'fasionClassfiction'\n",
    "modelName = 'lenet{}'.format('_bn' if bn else '')\n",
    "JST = timezone(timedelta(hours=+9), 'JST')\n",
    "now = datetime.now(JST)\n",
    "nowStr = now.strftime(\"%Y%m%d_%H%M%S\")\n",
    "showImgCount = 10\n",
    "\n",
    "imgHeight = 224\n",
    "imgWidth = 224\n",
    "imgChannel = 3\n",
    "imgShape = [-1, imgHeight, imgWidth, imgChannel]\n",
    "labelSize = 13\n",
    "tfrecordPath = './img/fashionDataset/tfrecord/dataset224.tfrecord'\n",
    "trainRatio = 0.7\n",
    "\n",
    "# hyper parameter\n",
    "bs = 32\n",
    "lr = 0.00001\n",
    "ep = 50\n",
    "\n",
    "logDir = '../logs/{}/{}/{}/'.format(taskName, modelName, nowStr)\n",
    "metadataDir = '{}metadata.tsv'.format(logDir)\n",
    "checkPointDir = '{}images.ckpt'.format(logDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T13:01:26.917548Z",
     "start_time": "2019-06-17T11:43:12.774425Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Train Accuracy: 0.6471 | Train Loss: 2.0467 | Test Accuracy: 0.7021 | Test Loss: 1.9877\n",
      "Epoch: 1 | Train Accuracy: 0.7357 | Train Loss: 1.9563 | Test Accuracy: 0.7501 | Test Loss: 1.9431\n",
      "Epoch: 2 | Train Accuracy: 0.7584 | Train Loss: 1.9335 | Test Accuracy: 0.7697 | Test Loss: 1.9228\n",
      "Epoch: 3 | Train Accuracy: 0.7744 | Train Loss: 1.9175 | Test Accuracy: 0.7754 | Test Loss: 1.9154\n",
      "Epoch: 4 | Train Accuracy: 0.7768 | Train Loss: 1.9135 | Test Accuracy: 0.7764 | Test Loss: 1.9143\n",
      "Epoch: 5 | Train Accuracy: 0.7787 | Train Loss: 1.9111 | Test Accuracy: 0.7811 | Test Loss: 1.9087\n",
      "Epoch: 6 | Train Accuracy: 0.7818 | Train Loss: 1.9074 | Test Accuracy: 0.7781 | Test Loss: 1.9110\n",
      "Epoch: 7 | Train Accuracy: 0.7829 | Train Loss: 1.9061 | Test Accuracy: 0.7852 | Test Loss: 1.9033\n",
      "Epoch: 8 | Train Accuracy: 0.7870 | Train Loss: 1.9014 | Test Accuracy: 0.7867 | Test Loss: 1.9013\n",
      "Epoch: 9 | Train Accuracy: 0.7868 | Train Loss: 1.9014 | Test Accuracy: 0.7845 | Test Loss: 1.9032\n",
      "Epoch: 10 | Train Accuracy: 0.7847 | Train Loss: 1.9034 | Test Accuracy: 0.7975 | Test Loss: 1.8903\n",
      "Epoch: 11 | Train Accuracy: 0.7859 | Train Loss: 1.9019 | Test Accuracy: 0.7924 | Test Loss: 1.8949\n",
      "Epoch: 12 | Train Accuracy: 0.7884 | Train Loss: 1.8993 | Test Accuracy: 0.7865 | Test Loss: 1.9029\n",
      "Epoch: 13 | Train Accuracy: 0.7968 | Train Loss: 1.8911 | Test Accuracy: 0.8197 | Test Loss: 1.8708\n",
      "Epoch: 14 | Train Accuracy: 0.8699 | Train Loss: 1.8212 | Test Accuracy: 0.8911 | Test Loss: 1.8000\n",
      "Epoch: 15 | Train Accuracy: 0.8914 | Train Loss: 1.7994 | Test Accuracy: 0.8916 | Test Loss: 1.7983\n",
      "Epoch: 16 | Train Accuracy: 0.8919 | Train Loss: 1.7982 | Test Accuracy: 0.8968 | Test Loss: 1.7927\n",
      "Epoch: 17 | Train Accuracy: 0.8988 | Train Loss: 1.7919 | Test Accuracy: 0.9077 | Test Loss: 1.7823\n",
      "Epoch: 18 | Train Accuracy: 0.9023 | Train Loss: 1.7879 | Test Accuracy: 0.8992 | Test Loss: 1.7905\n",
      "Epoch: 19 | Train Accuracy: 0.9022 | Train Loss: 1.7874 | Test Accuracy: 0.8997 | Test Loss: 1.7900\n",
      "Epoch: 20 | Train Accuracy: 0.9087 | Train Loss: 1.7814 | Test Accuracy: 0.9151 | Test Loss: 1.7745\n",
      "Epoch: 21 | Train Accuracy: 0.9127 | Train Loss: 1.7770 | Test Accuracy: 0.9144 | Test Loss: 1.7755\n",
      "Epoch: 22 | Train Accuracy: 0.9154 | Train Loss: 1.7742 | Test Accuracy: 0.9144 | Test Loss: 1.7749\n",
      "Epoch: 23 | Train Accuracy: 0.9136 | Train Loss: 1.7761 | Test Accuracy: 0.9106 | Test Loss: 1.7792\n",
      "Epoch: 24 | Train Accuracy: 0.9159 | Train Loss: 1.7735 | Test Accuracy: 0.9137 | Test Loss: 1.7761\n",
      "Epoch: 25 | Train Accuracy: 0.9164 | Train Loss: 1.7729 | Test Accuracy: 0.9172 | Test Loss: 1.7720\n",
      "Epoch: 26 | Train Accuracy: 0.9177 | Train Loss: 1.7714 | Test Accuracy: 0.9159 | Test Loss: 1.7736\n",
      "Epoch: 27 | Train Accuracy: 0.9166 | Train Loss: 1.7728 | Test Accuracy: 0.9167 | Test Loss: 1.7727\n",
      "Epoch: 28 | Train Accuracy: 0.9139 | Train Loss: 1.7753 | Test Accuracy: 0.9188 | Test Loss: 1.7702\n",
      "Epoch: 29 | Train Accuracy: 0.9177 | Train Loss: 1.7713 | Test Accuracy: 0.9206 | Test Loss: 1.7682\n",
      "Epoch: 30 | Train Accuracy: 0.9185 | Train Loss: 1.7705 | Test Accuracy: 0.9205 | Test Loss: 1.7685\n",
      "Epoch: 31 | Train Accuracy: 0.9173 | Train Loss: 1.7717 | Test Accuracy: 0.9161 | Test Loss: 1.7729\n",
      "Epoch: 32 | Train Accuracy: 0.9174 | Train Loss: 1.7715 | Test Accuracy: 0.9184 | Test Loss: 1.7707\n",
      "Epoch: 33 | Train Accuracy: 0.9178 | Train Loss: 1.7709 | Test Accuracy: 0.9187 | Test Loss: 1.7702\n",
      "Epoch: 34 | Train Accuracy: 0.9172 | Train Loss: 1.7715 | Test Accuracy: 0.9222 | Test Loss: 1.7664\n",
      "Epoch: 35 | Train Accuracy: 0.9169 | Train Loss: 1.7719 | Test Accuracy: 0.9219 | Test Loss: 1.7666\n",
      "Epoch: 36 | Train Accuracy: 0.9198 | Train Loss: 1.7689 | Test Accuracy: 0.9153 | Test Loss: 1.7732\n",
      "Epoch: 37 | Train Accuracy: 0.9188 | Train Loss: 1.7698 | Test Accuracy: 0.9184 | Test Loss: 1.7700\n",
      "Epoch: 38 | Train Accuracy: 0.9198 | Train Loss: 1.7688 | Test Accuracy: 0.9168 | Test Loss: 1.7716\n",
      "Epoch: 39 | Train Accuracy: 0.9182 | Train Loss: 1.7705 | Test Accuracy: 0.9227 | Test Loss: 1.7659\n",
      "Epoch: 40 | Train Accuracy: 0.9183 | Train Loss: 1.7704 | Test Accuracy: 0.9195 | Test Loss: 1.7690\n",
      "Epoch: 41 | Train Accuracy: 0.9217 | Train Loss: 1.7669 | Test Accuracy: 0.9197 | Test Loss: 1.7692\n",
      "Epoch: 42 | Train Accuracy: 0.9208 | Train Loss: 1.7677 | Test Accuracy: 0.9246 | Test Loss: 1.7639\n",
      "Epoch: 43 | Train Accuracy: 0.9201 | Train Loss: 1.7687 | Test Accuracy: 0.9238 | Test Loss: 1.7646\n",
      "Epoch: 44 | Train Accuracy: 0.9192 | Train Loss: 1.7692 | Test Accuracy: 0.9249 | Test Loss: 1.7636\n",
      "Epoch: 45 | Train Accuracy: 0.9203 | Train Loss: 1.7682 | Test Accuracy: 0.9230 | Test Loss: 1.7653\n",
      "Epoch: 46 | Train Accuracy: 0.9189 | Train Loss: 1.7696 | Test Accuracy: 0.9230 | Test Loss: 1.7654\n",
      "Epoch: 47 | Train Accuracy: 0.9211 | Train Loss: 1.7674 | Test Accuracy: 0.9206 | Test Loss: 1.7675\n",
      "Epoch: 48 | Train Accuracy: 0.9192 | Train Loss: 1.7690 | Test Accuracy: 0.9180 | Test Loss: 1.7705\n",
      "Epoch: 49 | Train Accuracy: 0.9203 | Train Loss: 1.7681 | Test Accuracy: 0.9195 | Test Loss: 1.7688\n"
     ]
    }
   ],
   "source": [
    "# main\n",
    "with tf.Graph().as_default():\n",
    "    # load data\n",
    "    with tf.variable_scope('tfrecord'):\n",
    "        tfrecord = data.TFRecord(tfrecordPath, labelSize)\n",
    "        dataset = tfrecord.toDataset()\n",
    "        # split dataset\n",
    "        tfrecord = data.TFRecord(tfrecordPath, labelSize)\n",
    "        dataset = tfrecord.toDataset()\n",
    "        trainSize, testSize, trainDataset, testDataset = tfrecord.splitDataset(bs)\n",
    "        trainIteration = trainSize // bs\n",
    "        testIteration = testSize // bs        \n",
    "        # TODO: data augmentation\n",
    "\n",
    "    # make iterator\n",
    "    with tf.variable_scope('train_data'):\n",
    "        trainIterator = trainDataset.make_initializable_iterator()\n",
    "        trainNextBatch = trainIterator.get_next(name='train_next_batch')\n",
    "        trainIteratorInitOp = trainIterator.initializer\n",
    "    with tf.variable_scope('test_data'):\n",
    "        testIterator = testDataset.make_initializable_iterator()\n",
    "        testNextBatch = testIterator.get_next(name='test_next_batch')\n",
    "        testIteratorInitOp = testIterator.initializer\n",
    "\n",
    "    \n",
    "    x = tf.placeholder(\"float\", [None, imgHeight, imgWidth, imgChannel], name='x')\n",
    "    y = tf.placeholder(\"float\", [None, labelSize], name='label')\n",
    "    isTrain = tf.placeholder(tf.bool, name='is_train')\n",
    "    \n",
    "    network = Lenet(x, inputReshapeTo=imgShape, labelSize=labelSize, batchNorm=bn, visualization=True)\n",
    "    _ = network.inference(isTrain)\n",
    "    cost = network.loss(y)\n",
    "    optimizer = tf.train.AdamOptimizer(lr)\n",
    "    accuracy = network.accuracy(y)\n",
    "    trainOp = network.training(cost, optimizer)\n",
    "    drawHist = tf.summary.merge_all('histogram')\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    config = tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True))\n",
    "    sess = tf.Session(config=config)\n",
    "    summaryWriter = tf.summary.FileWriter(logDir, graph=sess.graph)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # Training cycle\n",
    "    for e in range(ep):\n",
    "        trainAvgAcc = trainAvgLoss = testAvgAcc = testAvgLoss = 0.\n",
    "        # train\n",
    "        sess.run(trainIteratorInitOp)\n",
    "        for i in range(trainIteration):\n",
    "            _, batchX, batchY = sess.run(trainNextBatch)\n",
    "            _, l, a = sess.run([trainOp, cost, accuracy], feed_dict={x: batchX, y: batchY, isTrain: True})\n",
    "            trainAvgAcc += a / trainIteration\n",
    "            trainAvgLoss += l / trainIteration\n",
    "\n",
    "        # validation\n",
    "        sess.run(testIteratorInitOp)\n",
    "        for i in range(testIteration):\n",
    "            _, testBatchX, testBatchY = sess.run(testNextBatch)\n",
    "            l, a, histogram = sess.run([cost, accuracy, drawHist], feed_dict={x: testBatchX, y: testBatchY, isTrain: False})\n",
    "            testAvgAcc += a / testIteration\n",
    "            testAvgLoss += l / testIteration\n",
    "\n",
    "        # tensorBoard\n",
    "        summaryWriter.add_summary(drawSclar('train', {'acc': trainAvgAcc, 'loss': trainAvgLoss}), global_step=e)\n",
    "        summaryWriter.add_summary(drawSclar('validation', {'acc': testAvgAcc, 'loss': testAvgLoss}), global_step=e)\n",
    "        summaryWriter.add_summary(histogram, global_step=e)\n",
    "        saver.save(sess, checkPointDir, global_step=e)\n",
    "        print('Epoch: {} | Train Accuracy: {:.4f} | Train Loss: {:.4f} | Test Accuracy: {:.4f} | Test Loss: {:.4f}'.format(e, trainAvgAcc, trainAvgLoss, testAvgAcc, testAvgLoss))\n",
    "    summaryWriter.close()\n",
    "    sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

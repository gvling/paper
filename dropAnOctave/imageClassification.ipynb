{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T11:00:44.009566Z",
     "start_time": "2019-06-13T11:00:30.873345Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from utils import data\n",
    "#from models.resnet import Resnet18\n",
    "#from models.lenetKai import Lenet\n",
    "from models.lenetOctave import Lenet\n",
    "from utils import visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-13T11:00:30.872Z"
    }
   },
   "outputs": [],
   "source": [
    "# const\n",
    "taskName = 'fasionClassfiction'\n",
    "modelName = 'octaveLenet_bn'\n",
    "JST = timezone(timedelta(hours=+9), 'JST')\n",
    "now = datetime.now(JST)\n",
    "nowStr = now.strftime(\"%Y%m%d_%H%M%S\")\n",
    "showImgCount = 10\n",
    "\n",
    "imgHeight = 224\n",
    "imgWidth = 224\n",
    "imgChannel = 3\n",
    "imgShape = [-1, imgHeight, imgWidth, imgChannel]\n",
    "labelSize = 13\n",
    "tfrecordPath = './img/fashionDataset/tfrecord/dataset224.tfrecord'\n",
    "trainRatio = 0.7\n",
    "\n",
    "# hyper parameter\n",
    "bs = 64\n",
    "lr = 0.0001\n",
    "ep = 50\n",
    "alpha = 0.25\n",
    "\n",
    "logDir = '../logs/{}/{}/{}/'.format(taskName, modelName, nowStr)\n",
    "metadataDir = '{}metadata.tsv'.format(logDir)\n",
    "checkPointDir = '{}images.ckpt'.format(logDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-13T11:00:30.877Z"
    },
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  (?, 224, 224, 3) (?, 112, 112, 3)\n",
      "octConInput:  (?, 224, 224, 3) (?, 112, 112, 3)\n",
      "octConKernel:  (5, 5, 3, 5) (5, 5, 3, 1)\n",
      "high2HighLogit:  (?, 224, 224, 5)\n",
      "high2LowLogit:  (?, 112, 112, 1)\n",
      "low2HighLogit:  (?, 224, 224, 5)\n",
      "low2LowLogit:  (?, 112, 112, 1)\n",
      "conv_1:  (?, 224, 224, 5) (?, 112, 112, 1)\n",
      "pool_1:  (?, 112, 112, 5) (?, 56, 56, 1)\n",
      "octConInput:  (?, 112, 112, 5) (?, 56, 56, 1)\n",
      "octConKernel:  (5, 5, 5, 12) (5, 5, 1, 4)\n",
      "high2HighLogit:  (?, 112, 112, 12)\n",
      "high2LowLogit:  (?, 56, 56, 4)\n",
      "low2HighLogit:  (?, 112, 112, 12)\n",
      "low2LowLogit:  (?, 56, 56, 4)\n",
      "conv_2:  (?, 112, 112, 12) (?, 56, 56, 4)\n",
      "pool_2:  (?, 56, 56, 12) (?, 28, 28, 4)\n",
      "flat:  (?, 37632) (?, 3136)\n",
      "Add:  (?, 40768)\n",
      "Epoch: 0 | Train Accuracy: 0.578125 | Validation Accuracy: 0.75\n",
      "Epoch: 1 | Train Accuracy: 0.59375 | Validation Accuracy: 0.671875\n",
      "Epoch: 2 | Train Accuracy: 0.75 | Validation Accuracy: 0.640625\n",
      "Epoch: 3 | Train Accuracy: 0.734375 | Validation Accuracy: 0.78125\n",
      "Epoch: 4 | Train Accuracy: 0.671875 | Validation Accuracy: 0.6875\n",
      "Epoch: 5 | Train Accuracy: 0.75 | Validation Accuracy: 0.765625\n",
      "Epoch: 6 | Train Accuracy: 0.859375 | Validation Accuracy: 0.6875\n",
      "Epoch: 7 | Train Accuracy: 0.71875 | Validation Accuracy: 0.78125\n"
     ]
    }
   ],
   "source": [
    "# main\n",
    "with tf.Graph().as_default():\n",
    "    # load data\n",
    "    with tf.variable_scope('tfrecord'):\n",
    "        tfrecord = data.TFRecord(tfrecordPath, labelSize)\n",
    "        dataset = tfrecord.toDataset()\n",
    "        # split dataset\n",
    "        tfrecord = data.TFRecord(tfrecordPath, labelSize)\n",
    "        dataset = tfrecord.toDataset()\n",
    "        trainSize, testSize, trainDataset, testDataset = tfrecord.splitDataset(bs)\n",
    "        trainIteration = trainSize // bs\n",
    "        testIteration = testSize // bs        \n",
    "        # TODO: data augmentation\n",
    "\n",
    "    # make iterator\n",
    "    with tf.variable_scope('train_data'):\n",
    "        trainIterator = trainDataset.make_initializable_iterator()\n",
    "        trainNextBatch = trainIterator.get_next(name='train_next_batch')\n",
    "        trainIteratorInitOp = trainIterator.initializer\n",
    "    with tf.variable_scope('test_data'):\n",
    "        testIterator = testDataset.make_initializable_iterator()\n",
    "        testNextBatch = testIterator.get_next(name='test_next_batch')\n",
    "        testIteratorInitOp = testIterator.initializer\n",
    "\n",
    "    \n",
    "    x = tf.placeholder(\"float\", [None, imgHeight, imgWidth, imgChannel], name='x')\n",
    "    y = tf.placeholder(\"float\", [None, labelSize], name='label')\n",
    "\n",
    "    #network = Resnet18(x, labelSize=labelSize)\n",
    "    network = Lenet(alpha, x, inputShape=imgShape, labelSize=labelSize)\n",
    "    cost = network.loss(y)\n",
    "    optimizer = tf.train.AdamOptimizer(lr)\n",
    "    accuracy = network.accuracy(y)\n",
    "    trainOp = network.training(cost, optimizer)\n",
    "\n",
    "    # tensor board\n",
    "    with tf.variable_scope('train'):\n",
    "        drawTrainAcc = tf.summary.scalar('acc', accuracy)\n",
    "        drawTrainLoss = tf.summary.scalar('loss', cost)\n",
    "        trainSummaryOp = tf.summary.merge([drawTrainAcc, drawTrainLoss])\n",
    "    with tf.variable_scope(\"validation\"):\n",
    "        drawValAcc = tf.summary.scalar('acc', accuracy)\n",
    "        drawValLoss = tf.summary.scalar('loss', cost)\n",
    "        valSummaryOp = tf.summary.merge([drawValAcc, drawValLoss])\n",
    "    \n",
    "    drawImage = tf.summary.image('train_images', tf.reshape(x, imgShape), showImgCount)\n",
    "    allVariables = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "    summaryOp = tf.summary.merge([drawImage])\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    sess = tf.Session()\n",
    "    summaryWriter = tf.summary.FileWriter(logDir, graph=sess.graph)\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Training cycle\n",
    "    for e in range(ep):\n",
    "        # train\n",
    "        sess.run(trainIteratorInitOp)\n",
    "        for i in range(trainIteration):\n",
    "            _, batchX, batchY = sess.run(trainNextBatch)\n",
    "            sess.run(trainOp, feed_dict={x: batchX, y: batchY})\n",
    "        # Display logs per epoch step\n",
    "        # TODO: coculate avg\n",
    "        trainSummary = sess.run([trainSummaryOp,summaryOp], feed_dict={x: batchX, y: batchY})\n",
    "        for summary in trainSummary:\n",
    "            summaryWriter.add_summary(summary, e)\n",
    "        # validation\n",
    "        sess.run(testIteratorInitOp)\n",
    "        for i in range(testIteration):\n",
    "            _, testBatchX, testBatchY = sess.run(testNextBatch)\n",
    "            sess.run([cost, accuracy], feed_dict={x: testBatchX, y: testBatchY})\n",
    "        # TODO: coculate avg\n",
    "        valSummary = sess.run([valSummaryOp], feed_dict={x: testBatchX, y: testBatchY})\n",
    "        for summary in valSummary:\n",
    "            summaryWriter.add_summary(summary, e)\n",
    "            \n",
    "        saver.save(sess, checkPointDir, global_step=e)\n",
    "        trainAcc = sess.run(accuracy, feed_dict={x: batchX, y: batchY})\n",
    "        valAcc = sess.run(accuracy, feed_dict={x: testBatchX, y: testBatchY})\n",
    "        print('Epoch: {} | Train Accuracy: {} | Validation Accuracy: {}'.format(e, trainAcc, valAcc))\n",
    "    summaryWriter.close()\n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

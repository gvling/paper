{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-18T01:40:43.103266Z",
     "start_time": "2019-06-18T01:40:36.817919Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from utils import data\n",
    "from models.lenet import LenetTF as Lenet\n",
    "from utils.visualization import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-18T01:40:36.819Z"
    }
   },
   "outputs": [],
   "source": [
    "bn = True\n",
    "# const\n",
    "taskName = 'fasionClassfiction'\n",
    "modelName = 'lenetTF{}'.format('_bn' if bn else '')\n",
    "JST = timezone(timedelta(hours=+9), 'JST')\n",
    "now = datetime.now(JST)\n",
    "nowStr = now.strftime(\"%Y%m%d_%H%M%S\")\n",
    "showImgCount = 10\n",
    "\n",
    "imgHeight = 224\n",
    "imgWidth = 224\n",
    "imgChannel = 3\n",
    "imgShape = [-1, imgHeight, imgWidth, imgChannel]\n",
    "labelSize = 13\n",
    "tfrecordPath = './img/fashionDataset/tfrecord/dataset224.tfrecord'\n",
    "trainRatio = 0.7\n",
    "\n",
    "# hyper parameter\n",
    "bs = 32\n",
    "lr = 0.00001\n",
    "ep = 50\n",
    "\n",
    "logDir = '../logs/{}/{}/{}/'.format(taskName, modelName, nowStr)\n",
    "metadataDir = '{}metadata.tsv'.format(logDir)\n",
    "checkPointDir = '{}images.ckpt'.format(logDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-18T01:40:36.821Z"
    },
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# main\n",
    "with tf.Graph().as_default():\n",
    "    # load data\n",
    "    with tf.variable_scope('tfrecord'):\n",
    "        tfrecord = data.TFRecord(tfrecordPath, labelSize)\n",
    "        dataset = tfrecord.toDataset()\n",
    "        # split dataset\n",
    "        tfrecord = data.TFRecord(tfrecordPath, labelSize)\n",
    "        dataset = tfrecord.toDataset()\n",
    "        trainSize, testSize, trainDataset, testDataset = tfrecord.splitDataset(bs)\n",
    "        trainIteration = trainSize // bs\n",
    "        testIteration = testSize // bs        \n",
    "        # TODO: data augmentation\n",
    "\n",
    "    # make iterator\n",
    "    with tf.variable_scope('train_data'):\n",
    "        trainIterator = trainDataset.make_initializable_iterator()\n",
    "        trainNextBatch = trainIterator.get_next(name='train_next_batch')\n",
    "        trainIteratorInitOp = trainIterator.initializer\n",
    "    with tf.variable_scope('test_data'):\n",
    "        testIterator = testDataset.make_initializable_iterator()\n",
    "        testNextBatch = testIterator.get_next(name='test_next_batch')\n",
    "        testIteratorInitOp = testIterator.initializer\n",
    "\n",
    "    \n",
    "    x = tf.placeholder(\"float\", [None, imgHeight, imgWidth, imgChannel], name='x')\n",
    "    y = tf.placeholder(\"float\", [None, labelSize], name='label')\n",
    "    isTrain = tf.placeholder(tf.bool, name='is_train')\n",
    "    \n",
    "    network = Lenet(x, inputReshapeTo=imgShape, labelSize=labelSize, batchNorm=bn, visualization=True)\n",
    "    _ = network.inference(isTrain)\n",
    "    cost = network.loss(y)\n",
    "    optimizer = tf.train.AdamOptimizer(lr)\n",
    "    accuracy = network.accuracy(y)\n",
    "    trainOp = network.training(cost, optimizer)\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    config = tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True))\n",
    "    sess = tf.Session(config=config)\n",
    "    summaryWriter = tf.summary.FileWriter(logDir, graph=sess.graph)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # Training cycle\n",
    "    for e in range(ep):\n",
    "        trainAvgAcc = trainAvgLoss = testAvgAcc = testAvgLoss = 0.\n",
    "        # train\n",
    "        sess.run(trainIteratorInitOp)\n",
    "        for i in range(trainIteration):\n",
    "            _, batchX, batchY = sess.run(trainNextBatch)\n",
    "            _, l, a = sess.run([trainOp, cost, accuracy], feed_dict={x: batchX, y: batchY, isTrain: True})\n",
    "            trainAvgAcc += a / trainIteration\n",
    "            trainAvgLoss += l / trainIteration\n",
    "\n",
    "        # validation\n",
    "        sess.run(testIteratorInitOp)\n",
    "        for i in range(testIteration):\n",
    "            _, testBatchX, testBatchY = sess.run(testNextBatch)\n",
    "            l, a = sess.run([cost, accuracy], feed_dict={x: testBatchX, y: testBatchY, isTrain: False})\n",
    "            testAvgAcc += a / testIteration\n",
    "            testAvgLoss += l / testIteration\n",
    "\n",
    "        # tensorBoard\n",
    "        summaryWriter.add_summary(drawSclar('train', {'acc': trainAvgAcc, 'loss': trainAvgLoss}), global_step=e)\n",
    "        summaryWriter.add_summary(drawSclar('validation', {'acc': testAvgAcc, 'loss': testAvgLoss}), global_step=e)\n",
    "        saver.save(sess, checkPointDir, global_step=e)\n",
    "        print('Epoch: {} | Train Accuracy: {:.4f} | Train Loss: {:.4f} | Test Accuracy: {:.4f} | Test Loss: {:.4f}'.format(e, trainAvgAcc, trainAvgLoss, testAvgAcc, testAvgLoss))\n",
    "    summaryWriter.close()\n",
    "    sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
